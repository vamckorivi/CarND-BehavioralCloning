{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#all the import statements here\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read driving_log.csv and the images(Udacity Training Set)\n",
    "\n",
    "data = pd.read_csv(\"./data/driving_log.csv\")\n",
    "#recovery data provided by Annie Flippo\n",
    "data_recovery = pd.read_csv(\"./IMG_recovery/driving_log_recovery.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model goes here.\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Flatten, Dense, Activation, Convolution2D, MaxPooling2D, Dropout, Lambda, ELU\n",
    "def keras_lab():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32,3,3,border_mode='valid', input_shape=(64,64,3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(43))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.compile('adam','mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def nvidia():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Lambda(lambda x: x/127.5 -1,input_shape = (64,64,3)))\n",
    "    model.add(Convolution2D(24, 5, 5, subsample=(2, 2), border_mode=\"valid\", init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(36, 5, 5,subsample=(2, 2),  border_mode=\"valid\", init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(48, 5, 5, subsample=(2, 2), border_mode=\"valid\", init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Convolution2D(64, 3, 3, subsample=(1, 1), border_mode=\"valid\", init='he_normal'))\n",
    "    model.add(Flatten())\n",
    "    model.add(ELU())\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(100, init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(50, init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, init='he_normal'))\n",
    "    model.add(ELU())\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, init='he_normal'))\n",
    "\n",
    "    adam = Adam(lr=0.001)\n",
    "    model.compile(optimizer=adam, loss='mse')\n",
    "#     model.compile('adam', 'mse')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#the functions here\n",
    "def preprocessed_data(row):\n",
    "    steering = row['steering']\n",
    "    #print(\"preprocess_daa\")\n",
    "    # randomly choose the camera to take the image from\n",
    "    camera = np.random.choice(['center', 'left', 'right'])\n",
    "\n",
    "    # adjust the steering angle for left anf right cameras\n",
    "    if camera == 'left':\n",
    "        steering += 0.25\n",
    "    elif camera == 'right':\n",
    "        steering -= 0.25\n",
    "\n",
    "    #print(camera)\n",
    "    image_loc = row[camera][0]\n",
    "    #print(image_loc)\n",
    "    image_loc = image_loc.strip()\n",
    "    #print(image_loc)\n",
    "    image = cv2.imread(image_loc)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    #image = np.array(image)\n",
    "    #print(\"hi1\")\n",
    "    # decide whether to horizontally flip the image:\n",
    "    # This is done to reduce the bias for turning left that is present in the training data\n",
    "    flip_prob = np.random.random()\n",
    "    if flip_prob > 0.5:\n",
    "        # flip the image and reverse the steering angle\n",
    "        steering = -1*steering\n",
    "        image = cv2.flip(image, 1)\n",
    "\n",
    "    # Crop, resize and normalize the image\n",
    "    #image = image[25:140, :, :]\n",
    "    image = image[55:135, :, :]\n",
    "    #image = cv2.resize(image,(208,66))\n",
    "    image = cv2.resize(image,(64,64))\n",
    "    #image  = image/255.-.5\n",
    "    #image  = image/127.5-1\n",
    "    return image, steering\n",
    "\n",
    "\n",
    "def preprocessed_valid_data(row):\n",
    "    steering = row['steering']\n",
    "    image_loc = row['center'][0]\n",
    "    #print(image_loc)\n",
    "    image_loc = image_loc.strip()\n",
    "    #print(image_loc)\n",
    "    image = cv2.imread(image_loc)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Crop, resize and normalize the image\n",
    "    #image = image[25:140, :, :]\n",
    "    image = image[55:135, :, :]\n",
    "    #image = cv2.resize(image,(208,66))\n",
    "    image = cv2.resize(image,(64,64))\n",
    "    #image  = image/127.5-1\n",
    "    return image, steering\n",
    "\n",
    "def train_generaotr(data_df):\n",
    "    #batch_images = np.zeros((batch_size, 66, 208, 3))\n",
    "    batch_images = np.zeros((batch_size, 64, 64, 3))\n",
    "    batch_angles = np.zeros(batch_size)\n",
    "    #print(\"in train\")\n",
    "    while True:\n",
    "        for i in range (batch_size):\n",
    "            # Randomly get a sample from the input data\n",
    "            #print(i)\n",
    "            idx = np.random.randint(len(data_df))\n",
    "\n",
    "            # reset_index sets this data_df starting row to 0\n",
    "            data_row = data_df.iloc[[idx]].reset_index()\n",
    "            img1, angle1 = preprocessed_data(data_row)\n",
    "            batch_images[i] = img1\n",
    "            batch_angles[i] = angle1\n",
    "            \n",
    "        yield batch_images, batch_angles\n",
    "        \n",
    "def valid_genertor(data_df):\n",
    "    #batch_images = np.zeros((batch_size, 66, 208, 3))\n",
    "    batch_images = np.zeros((batch_size, 64, 64, 3))\n",
    "    batch_angles = np.zeros(batch_size)\n",
    "    #print(\"in train\")\n",
    "    while True:\n",
    "        for i in range (batch_size):\n",
    "            # Randomly get a sample from the input data\n",
    "            #print(i)\n",
    "            idx = np.random.randint(len(data_df))\n",
    "\n",
    "            # reset_index sets this data_df starting row to 0\n",
    "            data_row = data_df.iloc[[idx]].reset_index()\n",
    "            img1, angle1 = preprocessed_valid_data(data_row)\n",
    "\n",
    "            batch_images[i] = img1\n",
    "            batch_angles[i] = angle1\n",
    "            \n",
    "        yield batch_images, batch_angles\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "#This piece of code is implemented with the help of annie flippo's blog\n",
    "#Also, training data is taken from annie flippo rather than generating it again\n",
    "data_right = []\n",
    "data_left = []\n",
    "data_center = []\n",
    "\n",
    "#iterating through the data\n",
    "for i in range(len(data)):\n",
    "    center_img = data[\"center\"][i]\n",
    "    left_img = data[\"left\"][i]\n",
    "    right_img = data[\"right\"][i]\n",
    "    steering_angle = data[\"steering\"][i]\n",
    "    \n",
    "    #tried different steering angle combinations like 0.15, 0.2,0.1 but 0.15 steering angle \n",
    "    #gave better results and went with it\n",
    "    if (steering_angle > 0.15):\n",
    "        data_right.append([center_img, left_img, right_img, steering_angle])\n",
    "        for i in range(10):\n",
    "            new_angle = steering_angle * (1.0 + np.random.uniform(-1, 1)/30.0)\n",
    "            data_right.append([center_img, left_img, right_img, new_angle])\n",
    "\n",
    "    elif (steering_angle < -0.15):\n",
    "        data_left.append([center_img, left_img, right_img, steering_angle])\n",
    "        for i in range(20):\n",
    "            new_angle = steering_angle * (1.0 + np.random.uniform(-1, 1)/30.0)\n",
    "            data_left.append([center_img, left_img, right_img, new_angle])\n",
    "\n",
    "    else:\n",
    "        if (steering_angle != 0):\n",
    "            for i in range(5):\n",
    "                new_angle = steering_angle * (1.0 + np.random.uniform(-1, 1)/30.0)\n",
    "                data_center.append([center_img, left_img, right_img, new_angle])\n",
    "\n",
    "#iterating through the recovery data provided by annie flippo\n",
    "for i in range(len(data_recovery)):\n",
    "    center_img = data_recovery[\"center\"][i]\n",
    "    left_img = data_recovery[\"left\"][i]\n",
    "    right_img = data_recovery[\"right\"][i]\n",
    "    steering_angle = data_recovery[\"steering\"][i]\n",
    "    \n",
    "    #tried different steering angle combinations like 0.15, 0.2,0.1 but 0.15 steering angle \n",
    "    #gave better results and went with it\n",
    "    if (steering_angle > 0.15):\n",
    "        data_right.append([center_img, left_img, right_img, steering_angle])\n",
    "        for i in range(10):\n",
    "            new_angle = steering_angle * (1.0 + np.random.uniform(-1, 1)/30.0)\n",
    "            data_right.append([center_img, left_img, right_img, new_angle])\n",
    "\n",
    "    elif (steering_angle < -0.15):\n",
    "        data_left.append([center_img, left_img, right_img, steering_angle])\n",
    "        for i in range(20):\n",
    "            new_angle = steering_angle * (1.0 + np.random.uniform(-1, 1)/30.0)\n",
    "            data_left.append([center_img, left_img, right_img, new_angle])\n",
    "\n",
    "    else:\n",
    "        if (steering_angle != 0):\n",
    "            for i in range(5):\n",
    "                new_angle = steering_angle * (1.0 + np.random.uniform(-1, 1)/30.0)\n",
    "                data_center.append([center_img, left_img, right_img, new_angle])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20224/20224 [==============================] - 65s - loss: 0.1628 - val_loss: 0.0864\n",
      "Epoch 2/15\n",
      "20224/20224 [==============================] - 59s - loss: 0.1293 - val_loss: 0.0774\n",
      "Epoch 3/15\n",
      "20224/20224 [==============================] - 58s - loss: 0.1213 - val_loss: 0.0635\n",
      "Epoch 4/15\n",
      "20224/20224 [==============================] - 58s - loss: 0.1204 - val_loss: 0.0615\n",
      "Epoch 5/15\n",
      "20224/20224 [==============================] - 59s - loss: 0.1108 - val_loss: 0.0642\n",
      "Epoch 6/15\n",
      "20224/20224 [==============================] - 59s - loss: 0.1112 - val_loss: 0.0649\n",
      "Epoch 7/15\n",
      "20224/20224 [==============================] - 61s - loss: 0.1045 - val_loss: 0.0551\n",
      "Epoch 8/15\n",
      "20224/20224 [==============================] - 58s - loss: 0.1020 - val_loss: 0.0565\n",
      "Epoch 9/15\n",
      "20224/20224 [==============================] - 59s - loss: 0.0974 - val_loss: 0.0509\n",
      "Epoch 10/15\n",
      "20224/20224 [==============================] - 58s - loss: 0.0951 - val_loss: 0.0570\n",
      "Epoch 11/15\n",
      "20224/20224 [==============================] - 59s - loss: 0.0907 - val_loss: 0.0531\n",
      "Epoch 12/15\n",
      "20224/20224 [==============================] - 58s - loss: 0.0902 - val_loss: 0.0545\n",
      "Epoch 13/15\n",
      "20224/20224 [==============================] - 59s - loss: 0.0872 - val_loss: 0.0516\n",
      "Epoch 14/15\n",
      "20224/20224 [==============================] - 58s - loss: 0.0855 - val_loss: 0.0504\n",
      "Epoch 15/15\n",
      "20224/20224 [==============================] - 59s - loss: 0.0855 - val_loss: 0.0510\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_center = pd.DataFrame(data_center, columns=[\"center\", \"left\", \"right\", \"steering\"])\n",
    "data_left = pd.DataFrame(data_left, columns=[\"center\", \"left\", \"right\", \"steering\"])\n",
    "data_right = pd.DataFrame(data_right, columns=[\"center\", \"left\", \"right\", \"steering\"])\n",
    "data = [data_center, data_left, data_right]\n",
    "data = pd.concat(data, ignore_index=True)\n",
    "\n",
    "\n",
    "                                   \n",
    "\n",
    "batch_size=256\n",
    "\n",
    "# data = data.sample(frac=1).reset_index(drop=True)\n",
    "#splitting data into 80%training, 20%validation\n",
    "# training_data_index = int(data.shape[0]*0.8)\n",
    "# training_data = data.loc[0:training_data_index-1]\n",
    "# validation_data = data.loc[training_data_index:]\n",
    "\n",
    "#splitting data into 80%training, 20%validation\n",
    "training_data, validation_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "training_data  = pd.DataFrame(training_data,columns=[\"center\", \"left\", \"right\", \"steering\"])\n",
    "validation_data  = pd.DataFrame(validation_data,columns=[\"center\", \"left\", \"right\", \"steering\"])\n",
    "\n",
    "val_size = len(validation_data)\n",
    "#print(training_data.shape)\n",
    "#print(validation_data.shape)\n",
    "\n",
    "#testing generator with yield\n",
    "#gener_exam = get_primes(5)\n",
    "#print(gener_exam)\n",
    "training_generaotr = train_generaotr(training_data)\n",
    "#print(train_generaotr)\n",
    "validation_generator = valid_genertor(validation_data)\n",
    "#print(validation_generator)\n",
    "model  = nvidia()\n",
    "#model  = get_model()\n",
    "#model  = keras_lab()\n",
    "\n",
    "history = model.fit_generator(training_generaotr, validation_data=validation_generator,\n",
    "                              samples_per_epoch=20224, nb_epoch=15, nb_val_samples=3000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "json_string = model.to_json()\n",
    "with open(\"model.json\", 'w') as outfile:\n",
    "    json.dump(json_string, outfile)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
